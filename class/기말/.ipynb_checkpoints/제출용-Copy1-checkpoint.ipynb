{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "sess = tf.Session()\n",
    "\n",
    "x = [[1,0,0,0,0,0],# 4*4  #안\n",
    "    [0,1,0,0,0,0], #녕\n",
    "    [0,0,1,0,0,0], #하\n",
    "    [0,0,0,1,0,0], #세\n",
    "    [0,0,0,0,1,0], #요\n",
    "    [0,0,0,0,0,1]] #\n",
    "\n",
    "y = [[0,1,0,0,0,0],#글자 \n",
    "    [1,0,0,0,0,0], #띄어쓰기\n",
    "    [0,1,0,0,0,0], #글자\n",
    "    [0,1,0,0,0,0], #글자\n",
    "    [0,1,0,0,0,0], #글자\n",
    "    [0,0,0,0,0,0]] \n",
    "\n",
    "\n",
    "\n",
    "c_ = tf.zeros([6,6])\n",
    "h_ = tf.zeros([6,6])\n",
    "\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 6])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, 6])\n",
    "W = tf.Variable(tf.random_normal([6, 1]))*0.5\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "\n",
    "#he\n",
    "#el\n",
    "#ll\n",
    "#lo\n",
    "\n",
    "seq_len = len(x) #len(x)cell 갯수, 인풋이 몇 덩어리인지\n",
    "num_units = len(sess.run(c_))  #len(sess.run((c_)))# hiddenlayer\n",
    "\n",
    "\n",
    "class lstm:\n",
    "    def build(c, h):\n",
    "        args = tf.concat((X,h), axis=1)\n",
    "#        print(args)\n",
    "\n",
    "        out_size = 4 * num_units\n",
    "        proj_size = args.shape[-1]\n",
    "#        print(out_size)\n",
    "#        print(proj_size)\n",
    "\n",
    "        weights = tf.ones([proj_size, out_size]) * 0.5\n",
    "#        print(weights)\n",
    "\n",
    "\n",
    "        out = tf.matmul(args, weights)\n",
    "#        print(out)\n",
    "\n",
    "        bias = tf.ones([out_size]) * 0.5\n",
    "#        print(bias)\n",
    "\n",
    "        concat = out + bias\n",
    "#        print(concat)\n",
    "\n",
    "        i, j, f, o = tf.split(concat, 4, 1)\n",
    "#        print(i)\n",
    "#        print(j)\n",
    "#        print(f)\n",
    "#        print(o)\n",
    "\n",
    "        g = tf.tanh(j)\n",
    "#        print(g)\n",
    "\n",
    "        def sigmoid_array(x):\n",
    "            return 1 / (1 + tf.exp(-x))\n",
    "\n",
    "        forget_bias = 1.0\n",
    "\n",
    "        sigmoid_f = sigmoid_array(f + forget_bias)\n",
    "#        print(sigmoid_f)\n",
    "\n",
    "        sigmoid_array(i) * g\n",
    "\n",
    "        new_c = c * sigmoid_f + sigmoid_array(i) * g\n",
    "#        print(new_c)\n",
    "\n",
    "        new_h = tf.tanh(new_c) * sigmoid_array(o)\n",
    "#        print(new_h)\n",
    "\n",
    "#        print('\\n new_h:',new_h)\n",
    "#        print('\\n new_c',new_c)\n",
    "\n",
    "#        print(res[1].h)\n",
    "#        print(res[1].c)\n",
    "\n",
    "        return new_c, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx = [[0,0,0,0,0,1],#\n",
    "    [0,0,0,0,1,0], #요\n",
    "    [0,0,0,1,0,0], #세\n",
    "    [0,0,1,0,0,0], #하\n",
    "    [0,1,0,0,0,0], #녕\n",
    "    [1,0,0,0,0,0]] #안\n",
    "\n",
    "by = [[0,1,0,0,0,0], # 4*4 #\n",
    "    [0,1,0,0,0,0], #\n",
    "    [0,1,0,0,0,0], # \n",
    "    [0,1,0,0,0,0], #\n",
    "    [1,0,0,0,0,0], #\n",
    "    [0,1,0,0,0,0]] #\n",
    "\n",
    "\n",
    "\n",
    "bc_ = tf.zeros([6,6])\n",
    "bh_ = tf.zeros([6,6])\n",
    "\n",
    "bW = tf.Variable(tf.random_normal([6, 1]))*0.5\n",
    "bb = tf.Variable(tf.random_normal([1]))\n",
    "bX = tf.placeholder(dtype=tf.float32, shape=[None, 6])\n",
    "bY = tf.placeholder(dtype=tf.float32, shape=[None, 6])\n",
    "class blstm:\n",
    "    def build(c, h):\n",
    "        args = tf.concat((X,h), axis=1)\n",
    "#        print(args)\n",
    "\n",
    "        out_size = 4 * num_units\n",
    "        proj_size = args.shape[-1]\n",
    "#        print(out_size)\n",
    "#        print(proj_size)\n",
    "\n",
    "        weights = tf.ones([proj_size, out_size]) * 0.5\n",
    "#        print(weights)\n",
    "\n",
    "\n",
    "        out = tf.matmul(args, weights)\n",
    "#        print(out)\n",
    "\n",
    "        bias = tf.ones([out_size]) * 0.5\n",
    "#        print(bias)\n",
    "\n",
    "        concat = out + bias\n",
    "#        print(concat)\n",
    "\n",
    "        i, j, f, o = tf.split(concat, 4, 1)\n",
    "#        print(i)\n",
    "#        print(j)\n",
    "#        print(f)\n",
    "#        print(o)\n",
    "\n",
    "        g = tf.tanh(j)\n",
    "#        print(g)\n",
    "\n",
    "        def sigmoid_array(x):\n",
    "            return 1 / (1 + tf.exp(-x))\n",
    "\n",
    "        forget_bias = 1.0\n",
    "\n",
    "        sigmoid_f = sigmoid_array(f + forget_bias)\n",
    "#        print(sigmoid_f)\n",
    "\n",
    "        sigmoid_array(i) * g\n",
    "\n",
    "        new_bc = c * sigmoid_f + sigmoid_array(i) * g\n",
    "#        print(new_c)\n",
    "\n",
    "        new_bh = tf.tanh(new_bc) * sigmoid_array(o)\n",
    "#        print(new_h)\n",
    "\n",
    "#        print('\\n new_h:',new_h)\n",
    "#        print('\\n new_c',new_c)\n",
    "\n",
    "#        print(res[1].h)\n",
    "#        print(res[1].c)\n",
    "\n",
    "        return new_bc, new_bh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########################flstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_c = tf.TensorArray(size=seq_len, dtype=tf.float32)\n",
    "ta_h = tf.TensorArray(size=seq_len, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def body(last_state, last_output, step, ta_c, ta_h):\n",
    "    \n",
    "    output = lstm.build(last_state, last_output)[0]\n",
    "    state = lstm.build(last_state, last_output)[1]\n",
    "    ta_c = ta_c.write(step, state)\n",
    "    ta_h = ta_h.write(step, output)\n",
    "    return state, output, tf.add(step, 1), ta_c, ta_h\n",
    "    \n",
    "\n",
    "timesteps = seq_len\n",
    "\n",
    "steps = lambda a, b, step, c, d: tf.less(step, timesteps)\n",
    "\n",
    "lstm_output, lstm_state, step, ta_c, ta_h = tf.while_loop(steps, body, (c_, h_, 0, ta_c, ta_h), parallel_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = lstm_output\n",
    "logits = tf.matmul(output, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################Back lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bta_c = tf.TensorArray(size=seq_len, dtype=tf.float32)\n",
    "bta_h = tf.TensorArray(size=seq_len, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbody(last_state, last_output, step, bta_c, bta_h):\n",
    "    \n",
    "    boutput = blstm.build(last_state, last_output)[0]\n",
    "    bstate = blstm.build(last_state, last_output)[1]\n",
    "    bta_c = bta_c.write(step, bstate)\n",
    "    bta_h = bta_h.write(step, boutput)\n",
    "    return bstate, boutput, tf.add(step, 1), bta_c, bta_h\n",
    "    \n",
    "\n",
    "timesteps = seq_len\n",
    "\n",
    "\n",
    "steps = lambda a, b, step, c, d: tf.less(step, timesteps)\n",
    "\n",
    "blstm_output, blstm_state, step, bta_c, bta_h = tf.while_loop(steps, bbody, (bc_, bh_, 0, bta_c, bta_h), parallel_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "boutput = blstm_output\n",
    "blogits = tf.matmul(boutput, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mean_square_error_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('mean_square_error'):\n",
    "    mean_square_error = tf.reduce_sum(tf.square(tf.subtract(Y, tf.unstack(logits, axis = 1))))\n",
    "tf.summary.scalar('mean_square_error', mean_square_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.0003)\n",
    "minimize = optimizer.minimize(mean_square_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'error_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('error'):\n",
    "    with tf.name_scope('mistakes'):\n",
    "        mistakes = tf.not_equal(Y, tf.round(tf.unstack(logits, axis = 1)))\n",
    "    with tf.name_scope('error'):\n",
    "        error = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n",
    "tf.summary.scalar('error', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "date = str(datetime.datetime.now())\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100 | incorrect  86.1% | mean squ error  43.9\n",
      "Epoch  200 | incorrect  86.1% | mean squ error  36.1\n",
      "Epoch  300 | incorrect  86.1% | mean squ error  29.6\n",
      "Epoch  400 | incorrect  86.1% | mean squ error  24.1\n",
      "Epoch  500 | incorrect  86.1% | mean squ error  19.6\n",
      "Epoch  600 | incorrect  86.1% | mean squ error  15.9\n",
      "Epoch  700 | incorrect  86.1% | mean squ error  13.0\n",
      "Epoch  800 | incorrect  86.1% | mean squ error  10.7\n",
      "Epoch  900 | incorrect  13.9% | mean squ error  8.9\n",
      "Epoch 1000 | incorrect  13.9% | mean squ error  7.5\n",
      "Epoch 1100 | incorrect  13.9% | mean squ error  6.5\n",
      "Epoch 1200 | incorrect  13.9% | mean squ error  5.8\n",
      "Epoch 1300 | incorrect  13.9% | mean squ error  5.3\n",
      "Epoch 1400 | incorrect  13.9% | mean squ error  4.9\n",
      "Epoch 1500 | incorrect  13.9% | mean squ error  4.7\n",
      "Epoch 1600 | incorrect  13.9% | mean squ error  4.5\n",
      "Epoch 1700 | incorrect  13.9% | mean squ error  4.4\n",
      "Epoch 1800 | incorrect  13.9% | mean squ error  4.4\n",
      "Epoch 1900 | incorrect  13.9% | mean squ error  4.3\n",
      "Epoch 2000 | incorrect  13.9% | mean squ error  4.3\n",
      "Epoch 2100 | incorrect  13.9% | mean squ error  4.3\n",
      "Epoch 2200 | incorrect  13.9% | mean squ error  4.3\n",
      "Epoch 2300 | incorrect  13.9% | mean squ error  4.3\n",
      "Epoch 2400 | incorrect  13.9% | mean squ error  4.3\n",
      "Epoch 2500 | incorrect  13.9% | mean squ error  4.3\n",
      "Epoch 2600 | incorrect  13.9% | mean squ error  4.3\n",
      "Epoch 2700 | incorrect  13.9% | mean squ error  4.3\n",
      "Epoch 2800 | incorrect  13.9% | mean squ error  4.3\n",
      "Epoch 2900 | incorrect  13.9% | mean squ error  4.3\n",
      "Epoch 3000 | incorrect  13.9% | mean squ error  4.3\n"
     ]
    }
   ],
   "source": [
    "epoch = 3000\n",
    "\n",
    "for i in range(epoch):\n",
    "    if (i + 1) % 100 == 0:\n",
    "        summary, incorrect, mean_squ_err = sess.run([merged, error, mean_square_error], {X:x, Y:y})\n",
    "        \n",
    "        print('Epoch {:4d} | incorrect {: 3.1f}% | mean squ error {: 3.1f}'.format(i + 1, incorrect * 100, mean_squ_err))\n",
    "    else:\n",
    "        summary, acc = sess.run([merged, error], {X:x, Y:y})\n",
    "\n",
    "\n",
    "    sess.run(minimize,{X:x, Y:y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bmean_square_error_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('bmean_square_error'):\n",
    "    bmean_square_error = tf.reduce_sum(tf.square(tf.subtract(Y, tf.unstack(blogits, axis = 1))))\n",
    "tf.summary.scalar('bmean_square_error', bmean_square_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "boptimizer = tf.train.AdamOptimizer(0.0003)\n",
    "bminimize = optimizer.minimize(mean_square_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'error_2:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('berror'):\n",
    "    with tf.name_scope('bmistakes'):\n",
    "        bmistakes = tf.not_equal(Y, tf.round(tf.unstack(blogits, axis = 1)))\n",
    "    with tf.name_scope('error'):\n",
    "        berror = tf.reduce_mean(tf.cast(bmistakes, tf.float32))\n",
    "tf.summary.scalar('error', berror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmerged = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100 | incorrect  83.3% | mean squ error  45.2\n",
      "Epoch  200 | incorrect  83.3% | mean squ error  37.3\n",
      "Epoch  300 | incorrect  83.3% | mean squ error  30.7\n",
      "Epoch  400 | incorrect  83.3% | mean squ error  25.2\n",
      "Epoch  500 | incorrect  83.3% | mean squ error  20.6\n",
      "Epoch  600 | incorrect  83.3% | mean squ error  16.9\n",
      "Epoch  700 | incorrect  83.3% | mean squ error  13.9\n",
      "Epoch  800 | incorrect  83.3% | mean squ error  11.6\n",
      "Epoch  900 | incorrect  83.3% | mean squ error  9.7\n",
      "Epoch 1000 | incorrect  16.7% | mean squ error  8.3\n",
      "Epoch 1100 | incorrect  16.7% | mean squ error  7.3\n",
      "Epoch 1200 | incorrect  16.7% | mean squ error  6.6\n",
      "Epoch 1300 | incorrect  16.7% | mean squ error  6.0\n",
      "Epoch 1400 | incorrect  16.7% | mean squ error  5.7\n",
      "Epoch 1500 | incorrect  16.7% | mean squ error  5.4\n",
      "Epoch 1600 | incorrect  16.7% | mean squ error  5.2\n",
      "Epoch 1700 | incorrect  16.7% | mean squ error  5.1\n",
      "Epoch 1800 | incorrect  16.7% | mean squ error  5.1\n",
      "Epoch 1900 | incorrect  16.7% | mean squ error  5.0\n",
      "Epoch 2000 | incorrect  16.7% | mean squ error  5.0\n",
      "Epoch 2100 | incorrect  16.7% | mean squ error  5.0\n",
      "Epoch 2200 | incorrect  16.7% | mean squ error  5.0\n",
      "Epoch 2300 | incorrect  16.7% | mean squ error  5.0\n",
      "Epoch 2400 | incorrect  16.7% | mean squ error  5.0\n",
      "Epoch 2500 | incorrect  16.7% | mean squ error  5.0\n",
      "Epoch 2600 | incorrect  16.7% | mean squ error  5.0\n",
      "Epoch 2700 | incorrect  16.7% | mean squ error  5.0\n",
      "Epoch 2800 | incorrect  16.7% | mean squ error  5.0\n",
      "Epoch 2900 | incorrect  16.7% | mean squ error  5.0\n",
      "Epoch 3000 | incorrect  16.7% | mean squ error  5.0\n"
     ]
    }
   ],
   "source": [
    "epoch = 3000\n",
    "\n",
    "for i in range(epoch):\n",
    "    if (i + 1) % 100 == 0:\n",
    "        bsummary, bincorrect, bmean_squ_err = sess.run([bmerged, berror, bmean_square_error], {X:bx, Y:by})\n",
    "        \n",
    "        print('Epoch {:4d} | incorrect {: 3.1f}% | mean squ error {: 3.1f}'.format(i + 1, bincorrect * 100, bmean_squ_err))\n",
    "    else:\n",
    "        summary, acc = sess.run([bmerged, berror], {X:bx, Y:by})\n",
    "\n",
    "\n",
    "    sess.run(minimize,{X:bx, Y:by})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = sess.run(tf.equal(sess.run(Y, feed_dict={X:x, Y:y}),sess.run(tf.round(tf.unstack(logits, axis = 1)),feed_dict={X:x, Y:y})))\n",
    "fw = sess.run(tf.one_hot(fw, 1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = sess.run(tf.equal(sess.run(Y, feed_dict={X:bx, Y:by}),sess.run(tf.round(tf.unstack(blogits, axis = 1)),feed_dict={X:bx, Y:by})))\n",
    "bw = sess.run(tf.one_hot(bw, 1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape\n",
    "\n",
    "fw = fw[0][0:5]\n",
    "bw = bw[0][1:6]\n",
    "\n",
    "fw = np.delete(fw, [0,2,3,4,5], axis=1)\n",
    "bw = np.delete(bw, [0,2,3,4,5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw#안녕 하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw#요세하 녕안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bi_Lstm_Output = np.column_stack((fw,bw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bi_Lstm_Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['안','녕','하','세','요']\n",
    "s_output = []\n",
    "\n",
    "for i in range(5):\n",
    "    s_output.append(sentence[i])\n",
    "    if Bi_Lstm_Output[i][0] == 0:\n",
    "        s_output.append(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['안', '녕', ' ', '하', '세', '요']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.reverse()\n",
    "bs_output = []\n",
    "\n",
    "for i in range(5):\n",
    "    bs_output.append(sentence[i])\n",
    "    if Bi_Lstm_Output[-i][1] == 0:\n",
    "        bs_output.append(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['요', '세', '하', ' ', '녕', '안']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0열은 foward 방향이고 1열은 backward 방향입니다.\n",
    "안녕^ 하세요\n",
    "요세하^ 녕안"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'^' 표시가 붙은 글자 다음에 공백이 오면 0을 출력하게 만든 모델입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1.8]",
   "language": "python",
   "name": "conda-env-tf1.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#AND\n",
    "input_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype='float32')\n",
    "label = np.array([[1,0],[1,0],[1,0],[0,1]], dtype='float32')\n",
    "\n",
    "#OR\n",
    "#input_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype='float32')\n",
    "#label = np.array([[1,0],[0,1],[0,1],[0,1]], dtype='float32')\n",
    "\n",
    "#XOR\n",
    "#input_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype='float32')\n",
    "#label = np.array([[1,0],[0,1],[0,1],[1,0]], dtype='float32')\n",
    "#XOR는 학습이 안됨\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None,2])\n",
    "Y_ = tf.placeholder(tf.float32, [None,2])\n",
    "lr = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([2,2]), dtype='float32')\n",
    "B = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "Ylogits = tf.matmul(X, W) + B\n",
    "Y = tf.nn.sigmoid(Ylogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.losses.mean_squared_error(Y, Y_)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "correct = tf.argmax(Y,1)\n",
    "train_step = tf.train.AdamOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: acrcuracy:0.75 loss: 0.26967293\n",
      "1: acrcuracy:0.75 loss: 0.26785892\n",
      "2: acrcuracy:0.75 loss: 0.26607028\n",
      "3: acrcuracy:0.75 loss: 0.26430798\n",
      "4: acrcuracy:0.75 loss: 0.26257282\n",
      "5: acrcuracy:0.75 loss: 0.2608657\n",
      "6: acrcuracy:0.75 loss: 0.2591873\n",
      "7: acrcuracy:0.75 loss: 0.2575383\n",
      "8: acrcuracy:0.75 loss: 0.25591904\n",
      "9: acrcuracy:0.75 loss: 0.25432998\n",
      "10: acrcuracy:0.75 loss: 0.25277123\n",
      "11: acrcuracy:0.75 loss: 0.25124276\n",
      "12: acrcuracy:0.75 loss: 0.24974443\n",
      "13: acrcuracy:0.75 loss: 0.24827573\n",
      "14: acrcuracy:0.75 loss: 0.2468361\n",
      "15: acrcuracy:0.75 loss: 0.24542467\n",
      "16: acrcuracy:0.75 loss: 0.24404041\n",
      "17: acrcuracy:0.75 loss: 0.24268207\n",
      "18: acrcuracy:0.75 loss: 0.24134824\n",
      "19: acrcuracy:0.75 loss: 0.24003732\n",
      "20: acrcuracy:0.75 loss: 0.23874778\n",
      "21: acrcuracy:0.75 loss: 0.23747775\n",
      "22: acrcuracy:0.75 loss: 0.23622566\n",
      "23: acrcuracy:0.75 loss: 0.23498979\n",
      "24: acrcuracy:0.75 loss: 0.23376855\n",
      "25: acrcuracy:0.75 loss: 0.23256055\n",
      "26: acrcuracy:0.75 loss: 0.23136438\n",
      "27: acrcuracy:0.75 loss: 0.23017898\n",
      "28: acrcuracy:0.75 loss: 0.22900328\n",
      "29: acrcuracy:0.75 loss: 0.22783652\n",
      "30: acrcuracy:0.75 loss: 0.22667801\n",
      "31: acrcuracy:0.75 loss: 0.22552714\n",
      "32: acrcuracy:0.75 loss: 0.22438356\n",
      "33: acrcuracy:0.75 loss: 0.22324693\n",
      "34: acrcuracy:0.75 loss: 0.222117\n",
      "35: acrcuracy:0.75 loss: 0.22099364\n",
      "36: acrcuracy:0.75 loss: 0.21987669\n",
      "37: acrcuracy:0.75 loss: 0.21876612\n",
      "38: acrcuracy:0.75 loss: 0.21766192\n",
      "39: acrcuracy:0.75 loss: 0.216564\n",
      "40: acrcuracy:0.75 loss: 0.21547244\n",
      "41: acrcuracy:0.75 loss: 0.21438727\n",
      "42: acrcuracy:0.75 loss: 0.21330848\n",
      "43: acrcuracy:0.75 loss: 0.21223617\n",
      "44: acrcuracy:0.75 loss: 0.21117032\n",
      "45: acrcuracy:0.75 loss: 0.21011096\n",
      "46: acrcuracy:0.75 loss: 0.20905823\n",
      "47: acrcuracy:0.75 loss: 0.20801204\n",
      "48: acrcuracy:0.75 loss: 0.20697248\n",
      "49: acrcuracy:0.75 loss: 0.20593959\n",
      "50: acrcuracy:0.75 loss: 0.20491338\n",
      "51: acrcuracy:0.75 loss: 0.2038939\n",
      "52: acrcuracy:0.75 loss: 0.20288113\n",
      "53: acrcuracy:0.75 loss: 0.20187509\n",
      "54: acrcuracy:0.75 loss: 0.20087583\n",
      "55: acrcuracy:0.75 loss: 0.19988328\n",
      "56: acrcuracy:0.75 loss: 0.19889753\n",
      "57: acrcuracy:0.75 loss: 0.19791849\n",
      "58: acrcuracy:0.75 loss: 0.19694623\n",
      "59: acrcuracy:0.75 loss: 0.1959807\n",
      "60: acrcuracy:0.75 loss: 0.1950219\n",
      "61: acrcuracy:0.75 loss: 0.1940698\n",
      "62: acrcuracy:0.75 loss: 0.19312441\n",
      "63: acrcuracy:0.75 loss: 0.1921857\n",
      "64: acrcuracy:0.75 loss: 0.19125366\n",
      "65: acrcuracy:0.75 loss: 0.19032821\n",
      "66: acrcuracy:0.75 loss: 0.18940942\n",
      "67: acrcuracy:0.75 loss: 0.18849716\n",
      "68: acrcuracy:0.75 loss: 0.18759146\n",
      "69: acrcuracy:0.75 loss: 0.18669227\n",
      "70: acrcuracy:0.75 loss: 0.18579957\n",
      "71: acrcuracy:0.75 loss: 0.18491329\n",
      "72: acrcuracy:0.75 loss: 0.18403342\n",
      "73: acrcuracy:0.75 loss: 0.18315989\n",
      "74: acrcuracy:0.75 loss: 0.1822927\n",
      "75: acrcuracy:0.75 loss: 0.18143183\n",
      "76: acrcuracy:0.75 loss: 0.18057716\n",
      "77: acrcuracy:0.75 loss: 0.17972869\n",
      "78: acrcuracy:0.75 loss: 0.17888638\n",
      "79: acrcuracy:0.75 loss: 0.17805018\n",
      "80: acrcuracy:0.75 loss: 0.17722003\n",
      "81: acrcuracy:0.75 loss: 0.1763959\n",
      "82: acrcuracy:0.75 loss: 0.17557776\n",
      "83: acrcuracy:0.75 loss: 0.17476553\n",
      "84: acrcuracy:0.75 loss: 0.17395914\n",
      "85: acrcuracy:0.75 loss: 0.17315865\n",
      "86: acrcuracy:0.75 loss: 0.17236389\n",
      "87: acrcuracy:0.75 loss: 0.17157489\n",
      "88: acrcuracy:0.75 loss: 0.17079157\n",
      "89: acrcuracy:0.75 loss: 0.17001387\n",
      "90: acrcuracy:0.75 loss: 0.16924182\n",
      "91: acrcuracy:0.75 loss: 0.16847527\n",
      "92: acrcuracy:0.75 loss: 0.16771427\n",
      "93: acrcuracy:1.0 loss: 0.16695869\n",
      "94: acrcuracy:1.0 loss: 0.16620854\n",
      "95: acrcuracy:1.0 loss: 0.16546376\n",
      "96: acrcuracy:1.0 loss: 0.16472429\n",
      "97: acrcuracy:1.0 loss: 0.16399011\n",
      "98: acrcuracy:1.0 loss: 0.16326116\n",
      "99: acrcuracy:1.0 loss: 0.16253738\n",
      "100: acrcuracy:1.0 loss: 0.16181879\n",
      "101: acrcuracy:1.0 loss: 0.16110528\n",
      "102: acrcuracy:1.0 loss: 0.16039684\n",
      "103: acrcuracy:1.0 loss: 0.15969342\n",
      "104: acrcuracy:1.0 loss: 0.15899497\n",
      "105: acrcuracy:1.0 loss: 0.15830147\n",
      "106: acrcuracy:1.0 loss: 0.15761289\n",
      "107: acrcuracy:1.0 loss: 0.15692914\n",
      "108: acrcuracy:1.0 loss: 0.15625021\n",
      "109: acrcuracy:1.0 loss: 0.15557608\n",
      "110: acrcuracy:1.0 loss: 0.15490668\n",
      "111: acrcuracy:1.0 loss: 0.15424198\n",
      "112: acrcuracy:1.0 loss: 0.15358196\n",
      "113: acrcuracy:1.0 loss: 0.15292656\n",
      "114: acrcuracy:1.0 loss: 0.15227574\n",
      "115: acrcuracy:1.0 loss: 0.1516295\n",
      "116: acrcuracy:1.0 loss: 0.15098774\n",
      "117: acrcuracy:1.0 loss: 0.15035045\n",
      "118: acrcuracy:1.0 loss: 0.14971763\n",
      "119: acrcuracy:1.0 loss: 0.14908922\n",
      "120: acrcuracy:1.0 loss: 0.14846516\n",
      "121: acrcuracy:1.0 loss: 0.14784545\n",
      "122: acrcuracy:1.0 loss: 0.14723003\n",
      "123: acrcuracy:1.0 loss: 0.14661886\n",
      "124: acrcuracy:1.0 loss: 0.14601192\n",
      "125: acrcuracy:1.0 loss: 0.1454092\n",
      "126: acrcuracy:1.0 loss: 0.1448106\n",
      "127: acrcuracy:1.0 loss: 0.14421615\n",
      "128: acrcuracy:1.0 loss: 0.14362577\n",
      "129: acrcuracy:1.0 loss: 0.14303946\n",
      "130: acrcuracy:1.0 loss: 0.14245713\n",
      "131: acrcuracy:1.0 loss: 0.14187881\n",
      "132: acrcuracy:1.0 loss: 0.1413045\n",
      "133: acrcuracy:1.0 loss: 0.14073402\n",
      "134: acrcuracy:1.0 loss: 0.14016747\n",
      "135: acrcuracy:1.0 loss: 0.13960478\n",
      "136: acrcuracy:1.0 loss: 0.1390459\n",
      "137: acrcuracy:1.0 loss: 0.1384908\n",
      "138: acrcuracy:1.0 loss: 0.13793945\n",
      "139: acrcuracy:1.0 loss: 0.13739184\n",
      "140: acrcuracy:1.0 loss: 0.1368479\n",
      "141: acrcuracy:1.0 loss: 0.13630764\n",
      "142: acrcuracy:1.0 loss: 0.13577099\n",
      "143: acrcuracy:1.0 loss: 0.13523795\n",
      "144: acrcuracy:1.0 loss: 0.13470848\n",
      "145: acrcuracy:1.0 loss: 0.13418254\n",
      "146: acrcuracy:1.0 loss: 0.13366008\n",
      "147: acrcuracy:1.0 loss: 0.13314113\n",
      "148: acrcuracy:1.0 loss: 0.1326256\n",
      "149: acrcuracy:1.0 loss: 0.13211349\n",
      "150: acrcuracy:1.0 loss: 0.13160475\n",
      "151: acrcuracy:1.0 loss: 0.13109937\n",
      "152: acrcuracy:1.0 loss: 0.13059732\n",
      "153: acrcuracy:1.0 loss: 0.13009855\n",
      "154: acrcuracy:1.0 loss: 0.12960306\n",
      "155: acrcuracy:1.0 loss: 0.12911078\n",
      "156: acrcuracy:1.0 loss: 0.12862173\n",
      "157: acrcuracy:1.0 loss: 0.12813583\n",
      "158: acrcuracy:1.0 loss: 0.1276531\n",
      "159: acrcuracy:1.0 loss: 0.12717351\n",
      "160: acrcuracy:1.0 loss: 0.12669699\n",
      "161: acrcuracy:1.0 loss: 0.12622356\n",
      "162: acrcuracy:1.0 loss: 0.12575315\n",
      "163: acrcuracy:1.0 loss: 0.12528574\n",
      "164: acrcuracy:1.0 loss: 0.12482132\n",
      "165: acrcuracy:1.0 loss: 0.12435989\n",
      "166: acrcuracy:1.0 loss: 0.12390135\n",
      "167: acrcuracy:1.0 loss: 0.123445734\n",
      "168: acrcuracy:1.0 loss: 0.12299301\n",
      "169: acrcuracy:1.0 loss: 0.12254313\n",
      "170: acrcuracy:1.0 loss: 0.12209608\n",
      "171: acrcuracy:1.0 loss: 0.12165183\n",
      "172: acrcuracy:1.0 loss: 0.12121035\n",
      "173: acrcuracy:1.0 loss: 0.12077163\n",
      "174: acrcuracy:1.0 loss: 0.12033564\n",
      "175: acrcuracy:1.0 loss: 0.119902365\n",
      "176: acrcuracy:1.0 loss: 0.11947176\n",
      "177: acrcuracy:1.0 loss: 0.11904381\n",
      "178: acrcuracy:1.0 loss: 0.11861849\n",
      "179: acrcuracy:1.0 loss: 0.11819577\n",
      "180: acrcuracy:1.0 loss: 0.11777565\n",
      "181: acrcuracy:1.0 loss: 0.11735809\n",
      "182: acrcuracy:1.0 loss: 0.11694305\n",
      "183: acrcuracy:1.0 loss: 0.11653054\n",
      "184: acrcuracy:1.0 loss: 0.116120525\n",
      "185: acrcuracy:1.0 loss: 0.11571298\n",
      "186: acrcuracy:1.0 loss: 0.11530787\n",
      "187: acrcuracy:1.0 loss: 0.1149052\n",
      "188: acrcuracy:1.0 loss: 0.114504926\n",
      "189: acrcuracy:1.0 loss: 0.114107035\n",
      "190: acrcuracy:1.0 loss: 0.11371152\n",
      "191: acrcuracy:1.0 loss: 0.11331834\n",
      "192: acrcuracy:1.0 loss: 0.11292747\n",
      "193: acrcuracy:1.0 loss: 0.112538904\n",
      "194: acrcuracy:1.0 loss: 0.11215262\n",
      "195: acrcuracy:1.0 loss: 0.11176859\n",
      "196: acrcuracy:1.0 loss: 0.11138679\n",
      "197: acrcuracy:1.0 loss: 0.11100723\n",
      "198: acrcuracy:1.0 loss: 0.11062986\n",
      "199: acrcuracy:1.0 loss: 0.11025467\n",
      "200: acrcuracy:1.0 loss: 0.10988164\n",
      "201: acrcuracy:1.0 loss: 0.10951074\n",
      "202: acrcuracy:1.0 loss: 0.109141976\n",
      "203: acrcuracy:1.0 loss: 0.1087753\n",
      "204: acrcuracy:1.0 loss: 0.10841073\n",
      "205: acrcuracy:1.0 loss: 0.108048216\n",
      "206: acrcuracy:1.0 loss: 0.10768774\n",
      "207: acrcuracy:1.0 loss: 0.10732931\n",
      "208: acrcuracy:1.0 loss: 0.10697289\n",
      "209: acrcuracy:1.0 loss: 0.10661846\n",
      "210: acrcuracy:1.0 loss: 0.106266014\n",
      "211: acrcuracy:1.0 loss: 0.10591552\n",
      "212: acrcuracy:1.0 loss: 0.10556697\n",
      "213: acrcuracy:1.0 loss: 0.105220355\n",
      "214: acrcuracy:1.0 loss: 0.10487565\n",
      "215: acrcuracy:1.0 loss: 0.10453284\n",
      "216: acrcuracy:1.0 loss: 0.10419187\n",
      "217: acrcuracy:1.0 loss: 0.10385281\n",
      "218: acrcuracy:1.0 loss: 0.103515565\n",
      "219: acrcuracy:1.0 loss: 0.10318017\n",
      "220: acrcuracy:1.0 loss: 0.10284658\n",
      "221: acrcuracy:1.0 loss: 0.10251477\n",
      "222: acrcuracy:1.0 loss: 0.10218476\n",
      "223: acrcuracy:1.0 loss: 0.101856515\n",
      "224: acrcuracy:1.0 loss: 0.101530015\n",
      "225: acrcuracy:1.0 loss: 0.10120526\n",
      "226: acrcuracy:1.0 loss: 0.10088221\n",
      "227: acrcuracy:1.0 loss: 0.100560896\n",
      "228: acrcuracy:1.0 loss: 0.10024127\n",
      "229: acrcuracy:1.0 loss: 0.099923305\n",
      "230: acrcuracy:1.0 loss: 0.09960702\n",
      "231: acrcuracy:1.0 loss: 0.09929238\n",
      "232: acrcuracy:1.0 loss: 0.09897937\n",
      "233: acrcuracy:1.0 loss: 0.098667994\n",
      "234: acrcuracy:1.0 loss: 0.09835823\n",
      "235: acrcuracy:1.0 loss: 0.098050065\n",
      "236: acrcuracy:1.0 loss: 0.097743474\n",
      "237: acrcuracy:1.0 loss: 0.09743846\n",
      "238: acrcuracy:1.0 loss: 0.09713499\n",
      "239: acrcuracy:1.0 loss: 0.09683307\n",
      "240: acrcuracy:1.0 loss: 0.09653269\n",
      "241: acrcuracy:1.0 loss: 0.096233815\n",
      "242: acrcuracy:1.0 loss: 0.095936455\n",
      "243: acrcuracy:1.0 loss: 0.0956406\n",
      "244: acrcuracy:1.0 loss: 0.09534623\n",
      "245: acrcuracy:1.0 loss: 0.0950533\n",
      "246: acrcuracy:1.0 loss: 0.094761856\n",
      "247: acrcuracy:1.0 loss: 0.09447185\n",
      "248: acrcuracy:1.0 loss: 0.09418328\n",
      "249: acrcuracy:1.0 loss: 0.09389613\n",
      "250: acrcuracy:1.0 loss: 0.093610406\n",
      "251: acrcuracy:1.0 loss: 0.093326055\n",
      "252: acrcuracy:1.0 loss: 0.093043104\n",
      "253: acrcuracy:1.0 loss: 0.09276154\n",
      "254: acrcuracy:1.0 loss: 0.092481345\n",
      "255: acrcuracy:1.0 loss: 0.09220252\n",
      "256: acrcuracy:1.0 loss: 0.09192501\n",
      "257: acrcuracy:1.0 loss: 0.091648854\n",
      "258: acrcuracy:1.0 loss: 0.09137402\n",
      "259: acrcuracy:1.0 loss: 0.09110051\n",
      "260: acrcuracy:1.0 loss: 0.090828285\n",
      "261: acrcuracy:1.0 loss: 0.090557374\n",
      "262: acrcuracy:1.0 loss: 0.09028774\n",
      "263: acrcuracy:1.0 loss: 0.09001937\n",
      "264: acrcuracy:1.0 loss: 0.08975227\n",
      "265: acrcuracy:1.0 loss: 0.08948643\n",
      "266: acrcuracy:1.0 loss: 0.08922182\n",
      "267: acrcuracy:1.0 loss: 0.08895848\n",
      "268: acrcuracy:1.0 loss: 0.088696346\n",
      "269: acrcuracy:1.0 loss: 0.08843543\n",
      "270: acrcuracy:1.0 loss: 0.088175714\n",
      "271: acrcuracy:1.0 loss: 0.087917216\n",
      "272: acrcuracy:1.0 loss: 0.08765989\n",
      "273: acrcuracy:1.0 loss: 0.08740376\n",
      "274: acrcuracy:1.0 loss: 0.087148786\n",
      "275: acrcuracy:1.0 loss: 0.08689499\n",
      "276: acrcuracy:1.0 loss: 0.08664233\n",
      "277: acrcuracy:1.0 loss: 0.08639084\n",
      "278: acrcuracy:1.0 loss: 0.08614047\n",
      "279: acrcuracy:1.0 loss: 0.08589123\n",
      "280: acrcuracy:1.0 loss: 0.08564313\n",
      "281: acrcuracy:1.0 loss: 0.08539612\n",
      "282: acrcuracy:1.0 loss: 0.08515024\n",
      "283: acrcuracy:1.0 loss: 0.08490543\n",
      "284: acrcuracy:1.0 loss: 0.08466172\n",
      "285: acrcuracy:1.0 loss: 0.08441908\n",
      "286: acrcuracy:1.0 loss: 0.08417754\n",
      "287: acrcuracy:1.0 loss: 0.08393705\n",
      "288: acrcuracy:1.0 loss: 0.08369762\n",
      "289: acrcuracy:1.0 loss: 0.08345923\n",
      "290: acrcuracy:1.0 loss: 0.08322189\n",
      "291: acrcuracy:1.0 loss: 0.08298559\n",
      "292: acrcuracy:1.0 loss: 0.08275031\n",
      "293: acrcuracy:1.0 loss: 0.08251605\n",
      "294: acrcuracy:1.0 loss: 0.08228282\n",
      "295: acrcuracy:1.0 loss: 0.08205058\n",
      "296: acrcuracy:1.0 loss: 0.08181934\n",
      "297: acrcuracy:1.0 loss: 0.0815891\n",
      "298: acrcuracy:1.0 loss: 0.08135985\n",
      "299: acrcuracy:1.0 loss: 0.08113158\n",
      "300: acrcuracy:1.0 loss: 0.080904275\n",
      "301: acrcuracy:1.0 loss: 0.08067793\n",
      "302: acrcuracy:1.0 loss: 0.08045255\n",
      "303: acrcuracy:1.0 loss: 0.08022811\n",
      "304: acrcuracy:1.0 loss: 0.08000463\n",
      "305: acrcuracy:1.0 loss: 0.07978208\n",
      "306: acrcuracy:1.0 loss: 0.07956049\n",
      "307: acrcuracy:1.0 loss: 0.0793398\n",
      "308: acrcuracy:1.0 loss: 0.07912004\n",
      "309: acrcuracy:1.0 loss: 0.07890119\n",
      "310: acrcuracy:1.0 loss: 0.07868325\n",
      "311: acrcuracy:1.0 loss: 0.07846621\n",
      "312: acrcuracy:1.0 loss: 0.07825006\n",
      "313: acrcuracy:1.0 loss: 0.078034826\n",
      "314: acrcuracy:1.0 loss: 0.07782046\n",
      "315: acrcuracy:1.0 loss: 0.077606976\n",
      "316: acrcuracy:1.0 loss: 0.07739436\n",
      "317: acrcuracy:1.0 loss: 0.077182606\n",
      "318: acrcuracy:1.0 loss: 0.076971725\n",
      "319: acrcuracy:1.0 loss: 0.076761685\n",
      "320: acrcuracy:1.0 loss: 0.076552525\n",
      "321: acrcuracy:1.0 loss: 0.07634419\n",
      "322: acrcuracy:1.0 loss: 0.07613669\n",
      "323: acrcuracy:1.0 loss: 0.075930044\n",
      "324: acrcuracy:1.0 loss: 0.0757242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325: acrcuracy:1.0 loss: 0.07551919\n",
      "326: acrcuracy:1.0 loss: 0.075315\n",
      "327: acrcuracy:1.0 loss: 0.075111635\n",
      "328: acrcuracy:1.0 loss: 0.07490907\n",
      "329: acrcuracy:1.0 loss: 0.074707314\n",
      "330: acrcuracy:1.0 loss: 0.07450634\n",
      "331: acrcuracy:1.0 loss: 0.074306175\n",
      "332: acrcuracy:1.0 loss: 0.0741068\n",
      "333: acrcuracy:1.0 loss: 0.073908195\n",
      "334: acrcuracy:1.0 loss: 0.07371037\n",
      "335: acrcuracy:1.0 loss: 0.07351333\n",
      "336: acrcuracy:1.0 loss: 0.07331705\n",
      "337: acrcuracy:1.0 loss: 0.07312154\n",
      "338: acrcuracy:1.0 loss: 0.072926775\n",
      "339: acrcuracy:1.0 loss: 0.07273278\n",
      "340: acrcuracy:1.0 loss: 0.072539546\n",
      "341: acrcuracy:1.0 loss: 0.072347045\n",
      "342: acrcuracy:1.0 loss: 0.07215528\n",
      "343: acrcuracy:1.0 loss: 0.07196426\n",
      "344: acrcuracy:1.0 loss: 0.071773976\n",
      "345: acrcuracy:1.0 loss: 0.07158442\n",
      "346: acrcuracy:1.0 loss: 0.07139557\n",
      "347: acrcuracy:1.0 loss: 0.07120746\n",
      "348: acrcuracy:1.0 loss: 0.07102005\n",
      "349: acrcuracy:1.0 loss: 0.07083337\n",
      "350: acrcuracy:1.0 loss: 0.07064739\n",
      "351: acrcuracy:1.0 loss: 0.07046211\n",
      "352: acrcuracy:1.0 loss: 0.07027752\n",
      "353: acrcuracy:1.0 loss: 0.07009363\n",
      "354: acrcuracy:1.0 loss: 0.06991044\n",
      "355: acrcuracy:1.0 loss: 0.06972793\n",
      "356: acrcuracy:1.0 loss: 0.06954611\n",
      "357: acrcuracy:1.0 loss: 0.069364965\n",
      "358: acrcuracy:1.0 loss: 0.06918448\n",
      "359: acrcuracy:1.0 loss: 0.069004685\n",
      "360: acrcuracy:1.0 loss: 0.06882555\n",
      "361: acrcuracy:1.0 loss: 0.06864708\n",
      "362: acrcuracy:1.0 loss: 0.06846927\n",
      "363: acrcuracy:1.0 loss: 0.068292126\n",
      "364: acrcuracy:1.0 loss: 0.06811564\n",
      "365: acrcuracy:1.0 loss: 0.06793977\n",
      "366: acrcuracy:1.0 loss: 0.067764565\n",
      "367: acrcuracy:1.0 loss: 0.06759001\n",
      "368: acrcuracy:1.0 loss: 0.06741609\n",
      "369: acrcuracy:1.0 loss: 0.0672428\n",
      "370: acrcuracy:1.0 loss: 0.06707014\n",
      "371: acrcuracy:1.0 loss: 0.06689811\n",
      "372: acrcuracy:1.0 loss: 0.0667267\n",
      "373: acrcuracy:1.0 loss: 0.066555925\n",
      "374: acrcuracy:1.0 loss: 0.066385746\n",
      "375: acrcuracy:1.0 loss: 0.06621619\n",
      "376: acrcuracy:1.0 loss: 0.06604725\n",
      "377: acrcuracy:1.0 loss: 0.06587891\n",
      "378: acrcuracy:1.0 loss: 0.065711185\n",
      "379: acrcuracy:1.0 loss: 0.065544054\n",
      "380: acrcuracy:1.0 loss: 0.06537753\n",
      "381: acrcuracy:1.0 loss: 0.065211594\n",
      "382: acrcuracy:1.0 loss: 0.06504624\n",
      "383: acrcuracy:1.0 loss: 0.064881496\n",
      "384: acrcuracy:1.0 loss: 0.06471732\n",
      "385: acrcuracy:1.0 loss: 0.06455374\n",
      "386: acrcuracy:1.0 loss: 0.06439073\n",
      "387: acrcuracy:1.0 loss: 0.0642283\n",
      "388: acrcuracy:1.0 loss: 0.06406644\n",
      "389: acrcuracy:1.0 loss: 0.06390515\n",
      "390: acrcuracy:1.0 loss: 0.063744426\n",
      "391: acrcuracy:1.0 loss: 0.06358427\n",
      "392: acrcuracy:1.0 loss: 0.06342467\n",
      "393: acrcuracy:1.0 loss: 0.06326564\n",
      "394: acrcuracy:1.0 loss: 0.063107155\n",
      "395: acrcuracy:1.0 loss: 0.062949225\n",
      "396: acrcuracy:1.0 loss: 0.06279185\n",
      "397: acrcuracy:1.0 loss: 0.06263502\n",
      "398: acrcuracy:1.0 loss: 0.062478736\n",
      "399: acrcuracy:1.0 loss: 0.062322985\n",
      "400: acrcuracy:1.0 loss: 0.062167786\n",
      "401: acrcuracy:1.0 loss: 0.062013116\n",
      "402: acrcuracy:1.0 loss: 0.061858986\n",
      "403: acrcuracy:1.0 loss: 0.06170538\n",
      "404: acrcuracy:1.0 loss: 0.061552305\n",
      "405: acrcuracy:1.0 loss: 0.061399765\n",
      "406: acrcuracy:1.0 loss: 0.06124772\n",
      "407: acrcuracy:1.0 loss: 0.06109622\n",
      "408: acrcuracy:1.0 loss: 0.06094523\n",
      "409: acrcuracy:1.0 loss: 0.060794767\n",
      "410: acrcuracy:1.0 loss: 0.060644798\n",
      "411: acrcuracy:1.0 loss: 0.060495347\n",
      "412: acrcuracy:1.0 loss: 0.060346413\n",
      "413: acrcuracy:1.0 loss: 0.060197975\n",
      "414: acrcuracy:1.0 loss: 0.06005004\n",
      "415: acrcuracy:1.0 loss: 0.059902616\n",
      "416: acrcuracy:1.0 loss: 0.05975568\n",
      "417: acrcuracy:1.0 loss: 0.05960924\n",
      "418: acrcuracy:1.0 loss: 0.0594633\n",
      "419: acrcuracy:1.0 loss: 0.059317842\n",
      "420: acrcuracy:1.0 loss: 0.059172884\n",
      "421: acrcuracy:1.0 loss: 0.059028395\n",
      "422: acrcuracy:1.0 loss: 0.058884405\n",
      "423: acrcuracy:1.0 loss: 0.058740884\n",
      "424: acrcuracy:1.0 loss: 0.058597855\n",
      "425: acrcuracy:1.0 loss: 0.058455296\n",
      "426: acrcuracy:1.0 loss: 0.058313217\n",
      "427: acrcuracy:1.0 loss: 0.058171615\n",
      "428: acrcuracy:1.0 loss: 0.05803048\n",
      "429: acrcuracy:1.0 loss: 0.057889804\n",
      "430: acrcuracy:1.0 loss: 0.05774961\n",
      "431: acrcuracy:1.0 loss: 0.057609875\n",
      "432: acrcuracy:1.0 loss: 0.057470597\n",
      "433: acrcuracy:1.0 loss: 0.057331786\n",
      "434: acrcuracy:1.0 loss: 0.05719342\n",
      "435: acrcuracy:1.0 loss: 0.057055525\n",
      "436: acrcuracy:1.0 loss: 0.05691808\n",
      "437: acrcuracy:1.0 loss: 0.056781076\n",
      "438: acrcuracy:1.0 loss: 0.056644525\n",
      "439: acrcuracy:1.0 loss: 0.05650843\n",
      "440: acrcuracy:1.0 loss: 0.056372773\n",
      "441: acrcuracy:1.0 loss: 0.05623756\n",
      "442: acrcuracy:1.0 loss: 0.056102797\n",
      "443: acrcuracy:1.0 loss: 0.055968467\n",
      "444: acrcuracy:1.0 loss: 0.05583457\n",
      "445: acrcuracy:1.0 loss: 0.05570111\n",
      "446: acrcuracy:1.0 loss: 0.05556808\n",
      "447: acrcuracy:1.0 loss: 0.05543549\n",
      "448: acrcuracy:1.0 loss: 0.055303328\n",
      "449: acrcuracy:1.0 loss: 0.05517158\n",
      "450: acrcuracy:1.0 loss: 0.055040266\n",
      "451: acrcuracy:1.0 loss: 0.054909393\n",
      "452: acrcuracy:1.0 loss: 0.05477893\n",
      "453: acrcuracy:1.0 loss: 0.05464888\n",
      "454: acrcuracy:1.0 loss: 0.05451925\n",
      "455: acrcuracy:1.0 loss: 0.054390047\n",
      "456: acrcuracy:1.0 loss: 0.05426126\n",
      "457: acrcuracy:1.0 loss: 0.054132864\n",
      "458: acrcuracy:1.0 loss: 0.054004893\n",
      "459: acrcuracy:1.0 loss: 0.05387734\n",
      "460: acrcuracy:1.0 loss: 0.053750187\n",
      "461: acrcuracy:1.0 loss: 0.053623434\n",
      "462: acrcuracy:1.0 loss: 0.0534971\n",
      "463: acrcuracy:1.0 loss: 0.05337115\n",
      "464: acrcuracy:1.0 loss: 0.053245608\n",
      "465: acrcuracy:1.0 loss: 0.05312047\n",
      "466: acrcuracy:1.0 loss: 0.05299572\n",
      "467: acrcuracy:1.0 loss: 0.052871376\n",
      "468: acrcuracy:1.0 loss: 0.052747417\n",
      "469: acrcuracy:1.0 loss: 0.05262386\n",
      "470: acrcuracy:1.0 loss: 0.052500676\n",
      "471: acrcuracy:1.0 loss: 0.052377902\n",
      "472: acrcuracy:1.0 loss: 0.052255504\n",
      "473: acrcuracy:1.0 loss: 0.052133482\n",
      "474: acrcuracy:1.0 loss: 0.052011866\n",
      "475: acrcuracy:1.0 loss: 0.051890604\n",
      "476: acrcuracy:1.0 loss: 0.051769737\n",
      "477: acrcuracy:1.0 loss: 0.051649258\n",
      "478: acrcuracy:1.0 loss: 0.051529154\n",
      "479: acrcuracy:1.0 loss: 0.051409427\n",
      "480: acrcuracy:1.0 loss: 0.051290058\n",
      "481: acrcuracy:1.0 loss: 0.051171076\n",
      "482: acrcuracy:1.0 loss: 0.05105246\n",
      "483: acrcuracy:1.0 loss: 0.05093421\n",
      "484: acrcuracy:1.0 loss: 0.050816335\n",
      "485: acrcuracy:1.0 loss: 0.05069882\n",
      "486: acrcuracy:1.0 loss: 0.050581675\n",
      "487: acrcuracy:1.0 loss: 0.0504649\n",
      "488: acrcuracy:1.0 loss: 0.05034848\n",
      "489: acrcuracy:1.0 loss: 0.050232425\n",
      "490: acrcuracy:1.0 loss: 0.050116725\n",
      "491: acrcuracy:1.0 loss: 0.05000138\n",
      "492: acrcuracy:1.0 loss: 0.049886398\n",
      "493: acrcuracy:1.0 loss: 0.049771763\n",
      "494: acrcuracy:1.0 loss: 0.04965749\n",
      "495: acrcuracy:1.0 loss: 0.049543567\n",
      "496: acrcuracy:1.0 loss: 0.04942999\n",
      "497: acrcuracy:1.0 loss: 0.04931677\n",
      "498: acrcuracy:1.0 loss: 0.049203895\n",
      "499: acrcuracy:1.0 loss: 0.049091365\n",
      "500: acrcuracy:1.0 loss: 0.048979178\n",
      "max test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = 0.0\n",
    "\n",
    "def training_step(i):#, update_test_data, update_train_data):\n",
    "    \n",
    "    global max_accuracy\n",
    "    \n",
    "    a, c, _ = sess.run([accuracy, cross_entropy, train_step], feed_dict = {X:input_data, Y_:label})\n",
    "    if(a>max_accuracy):\n",
    "        max_accuracy = a\n",
    "    print(str(i) + \": acrcuracy:\" + str(a) + \" loss: \" + str(c))\n",
    "    \n",
    "for i in range(500+1):\n",
    "    training_step(i)\n",
    "print(\"max test accuracy: \" + str(max_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.] 0\n",
      "[0. 1.] 0\n",
      "[1. 0.] 0\n",
      "[1. 1.] 1\n"
     ]
    }
   ],
   "source": [
    "y = sess.run(correct, feed_dict = {X:input_data, Y_:label})\n",
    "for i in range(4):\n",
    "    print(input_data[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1.8]",
   "language": "python",
   "name": "conda-env-tf1.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = read_data_sets(\"data\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"parameter\"\n",
    "epoch = 25\n",
    "batch_size = 100\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "lr = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "X2 = tf.reshape(X, [-1, 784])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784, 512], stddev=0.1))\n",
    "b1 = tf.Variable(tf.random_normal([512], stddev=0.1))\n",
    "L1 = tf.nn.relu(tf.matmul(X2, W1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([512, 256], stddev=0.1))\n",
    "b2 = tf.Variable(tf.random_normal([256], stddev=0.1))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    " \n",
    "W3 = tf.Variable(tf.random_normal([256, 128], stddev=0.1))\n",
    "b3 = tf.Variable(tf.random_normal([128], stddev=0.1))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([128, 64], stddev=0.1))\n",
    "b4 = tf.Variable(tf.random_normal([64], stddev=0.1))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "W5 = tf.Variable(tf.random_normal([64, 10], stddev=0.1))\n",
    "b5 = tf.Variable(tf.random_normal([10], stddev=0.1))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "H = tf.nn.relu(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))*100\n",
    "train = tf.train.AdamOptimizer(lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(H,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.9547 15.41134\n",
      "2\n",
      "0.9704 11.56538\n",
      "3\n",
      "0.969 10.993514\n",
      "4\n",
      "0.974 9.542222\n",
      "5\n",
      "0.9751 9.660397\n",
      "6\n",
      "0.9759 9.708768\n",
      "7\n",
      "0.9758 9.491272\n",
      "8\n",
      "0.9793 8.220504\n",
      "9\n",
      "0.9803 8.685564\n",
      "10\n",
      "0.9786 8.454345\n",
      "11\n",
      "0.9798 9.168415\n",
      "12\n",
      "0.9801 9.127578\n",
      "13\n",
      "0.9794 10.479462\n",
      "14\n",
      "0.9812 9.601561\n",
      "15\n",
      "0.9819 8.669195\n",
      "16\n",
      "0.9808 9.184787\n",
      "17\n",
      "0.98 9.897798\n",
      "18\n",
      "0.981 9.61474\n",
      "19\n",
      "0.9803 9.766223\n",
      "20\n",
      "0.9801 11.040229\n",
      "21\n",
      "0.9803 10.977468\n",
      "22\n",
      "0.9804 11.1121435\n",
      "23\n",
      "0.9815 11.8105955\n",
      "24\n",
      "0.9789 11.584189\n",
      "25\n",
      "0.9836 9.841492\n"
     ]
    }
   ],
   "source": [
    "avg_cost = 0\n",
    "c = 0\n",
    "for e in range(epoch):\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    print(e+1)\n",
    "    global avg_cost\n",
    "    global c\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        max_lr = 0.003\n",
    "        min_lr = 0.0001\n",
    "        decay_speed = 2000\n",
    "        learning_late = min_lr+(max_lr-min_lr)*math.exp(-i/decay_speed)\n",
    "        \n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train, feed_dict={X:batch_xs, Y:batch_ys, keep_prob:0.7, lr:learning_late})\n",
    "        avg_cost += c/total_batch\n",
    "    a, c = sess.run([accuracy, cost], feed_dict={X:mnist.test.images, Y:mnist.test.labels, keep_prob:1, lr:learning_late})\n",
    "    print(a, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1.8]",
   "language": "python",
   "name": "conda-env-tf1.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

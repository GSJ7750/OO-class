{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#AND\n",
    "#input_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype='float32')\n",
    "#label = np.array([[0],[1],[1],[1]], dtype='float32')\n",
    "\n",
    "#OR\n",
    "input_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype='float32')\n",
    "label = np.array([[0],[1],[1],[1]], dtype='float32')\n",
    "\n",
    "#XOR\n",
    "#input_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype='float32')\n",
    "#label = np.array([[0],[1],[1],[0]], dtype='float32')\n",
    "#XOR는 학습이 안됨\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None,2])\n",
    "Y_ = tf.placeholder(tf.float32, [None,1])\n",
    "lr = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([2,1]), dtype='float32')\n",
    "B = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "Ylogits = tf.matmul(X, W) + B\n",
    "Y = tf.nn.sigmoid(Ylogits)\n",
    "Y2 = tf.round(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf_1.8\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.losses.mean_squared_error(Y, Y_)\n",
    "\n",
    "correct_prediction = tf.equal(Y2, Y_)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "predict = Y2\n",
    "train_step = tf.train.AdamOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: acrcuracy:0.75 loss: 0.24249087\n",
      "1: acrcuracy:0.5 loss: 0.23955974\n",
      "2: acrcuracy:0.5 loss: 0.23667811\n",
      "3: acrcuracy:0.5 loss: 0.23384735\n",
      "4: acrcuracy:0.5 loss: 0.23106858\n",
      "5: acrcuracy:0.5 loss: 0.22834288\n",
      "6: acrcuracy:0.5 loss: 0.22567122\n",
      "7: acrcuracy:0.5 loss: 0.22305445\n",
      "8: acrcuracy:0.5 loss: 0.22049333\n",
      "9: acrcuracy:0.5 loss: 0.21798845\n",
      "10: acrcuracy:0.5 loss: 0.21554029\n",
      "11: acrcuracy:0.5 loss: 0.21314922\n",
      "12: acrcuracy:0.5 loss: 0.21081552\n",
      "13: acrcuracy:0.5 loss: 0.20853932\n",
      "14: acrcuracy:0.5 loss: 0.20632057\n",
      "15: acrcuracy:0.5 loss: 0.2041592\n",
      "16: acrcuracy:0.5 loss: 0.20205496\n",
      "17: acrcuracy:0.5 loss: 0.20000751\n",
      "18: acrcuracy:0.5 loss: 0.1980164\n",
      "19: acrcuracy:0.5 loss: 0.1960811\n",
      "20: acrcuracy:0.5 loss: 0.19420096\n",
      "21: acrcuracy:0.5 loss: 0.19237523\n",
      "22: acrcuracy:0.5 loss: 0.1906031\n",
      "23: acrcuracy:0.5 loss: 0.18888369\n",
      "24: acrcuracy:0.5 loss: 0.18721603\n",
      "25: acrcuracy:0.5 loss: 0.18559907\n",
      "26: acrcuracy:0.5 loss: 0.18403175\n",
      "27: acrcuracy:0.5 loss: 0.18251291\n",
      "28: acrcuracy:0.5 loss: 0.18104139\n",
      "29: acrcuracy:0.5 loss: 0.17961599\n",
      "30: acrcuracy:0.5 loss: 0.1782354\n",
      "31: acrcuracy:0.5 loss: 0.17689843\n",
      "32: acrcuracy:0.5 loss: 0.17560373\n",
      "33: acrcuracy:0.5 loss: 0.17435\n",
      "34: acrcuracy:0.5 loss: 0.17313597\n",
      "35: acrcuracy:0.5 loss: 0.1719603\n",
      "36: acrcuracy:0.5 loss: 0.17082167\n",
      "37: acrcuracy:0.5 loss: 0.16971874\n",
      "38: acrcuracy:0.5 loss: 0.16865028\n",
      "39: acrcuracy:0.5 loss: 0.167615\n",
      "40: acrcuracy:0.5 loss: 0.16661152\n",
      "41: acrcuracy:0.5 loss: 0.16563867\n",
      "42: acrcuracy:0.5 loss: 0.16469522\n",
      "43: acrcuracy:0.75 loss: 0.16377994\n",
      "44: acrcuracy:0.75 loss: 0.16289164\n",
      "45: acrcuracy:0.75 loss: 0.16202916\n",
      "46: acrcuracy:0.75 loss: 0.16119139\n",
      "47: acrcuracy:0.75 loss: 0.16037717\n",
      "48: acrcuracy:0.75 loss: 0.15958546\n",
      "49: acrcuracy:0.75 loss: 0.15881525\n",
      "50: acrcuracy:0.75 loss: 0.15806545\n",
      "51: acrcuracy:0.75 loss: 0.15733515\n",
      "52: acrcuracy:0.75 loss: 0.15662336\n",
      "53: acrcuracy:0.75 loss: 0.15592916\n",
      "54: acrcuracy:0.75 loss: 0.15525168\n",
      "55: acrcuracy:0.75 loss: 0.15459007\n",
      "56: acrcuracy:0.75 loss: 0.1539435\n",
      "57: acrcuracy:0.75 loss: 0.15331116\n",
      "58: acrcuracy:0.75 loss: 0.15269235\n",
      "59: acrcuracy:0.75 loss: 0.15208624\n",
      "60: acrcuracy:0.75 loss: 0.15149222\n",
      "61: acrcuracy:0.75 loss: 0.15090962\n",
      "62: acrcuracy:0.75 loss: 0.15033768\n",
      "63: acrcuracy:0.75 loss: 0.14977592\n",
      "64: acrcuracy:0.75 loss: 0.14922372\n",
      "65: acrcuracy:0.75 loss: 0.14868045\n",
      "66: acrcuracy:0.75 loss: 0.14814568\n",
      "67: acrcuracy:0.75 loss: 0.14761885\n",
      "68: acrcuracy:0.75 loss: 0.14709945\n",
      "69: acrcuracy:0.75 loss: 0.14658703\n",
      "70: acrcuracy:0.75 loss: 0.14608122\n",
      "71: acrcuracy:0.75 loss: 0.14558151\n",
      "72: acrcuracy:0.75 loss: 0.14508756\n",
      "73: acrcuracy:0.75 loss: 0.14459899\n",
      "74: acrcuracy:0.75 loss: 0.1441154\n",
      "75: acrcuracy:0.75 loss: 0.14363652\n",
      "76: acrcuracy:0.75 loss: 0.14316201\n",
      "77: acrcuracy:0.75 loss: 0.14269154\n",
      "78: acrcuracy:0.75 loss: 0.14222488\n",
      "79: acrcuracy:0.75 loss: 0.1417617\n",
      "80: acrcuracy:0.75 loss: 0.14130183\n",
      "81: acrcuracy:0.75 loss: 0.14084496\n",
      "82: acrcuracy:0.75 loss: 0.1403909\n",
      "83: acrcuracy:0.75 loss: 0.13993941\n",
      "84: acrcuracy:0.75 loss: 0.13949037\n",
      "85: acrcuracy:0.75 loss: 0.13904351\n",
      "86: acrcuracy:0.75 loss: 0.13859873\n",
      "87: acrcuracy:0.75 loss: 0.13815583\n",
      "88: acrcuracy:0.75 loss: 0.13771465\n",
      "89: acrcuracy:0.75 loss: 0.13727508\n",
      "90: acrcuracy:0.75 loss: 0.13683699\n",
      "91: acrcuracy:0.75 loss: 0.13640022\n",
      "92: acrcuracy:0.75 loss: 0.13596477\n",
      "93: acrcuracy:0.75 loss: 0.13553037\n",
      "94: acrcuracy:0.75 loss: 0.13509704\n",
      "95: acrcuracy:0.75 loss: 0.13466465\n",
      "96: acrcuracy:0.75 loss: 0.13423319\n",
      "97: acrcuracy:0.75 loss: 0.13380249\n",
      "98: acrcuracy:0.75 loss: 0.13337252\n",
      "99: acrcuracy:0.75 loss: 0.13294323\n",
      "100: acrcuracy:0.75 loss: 0.13251455\n",
      "101: acrcuracy:0.75 loss: 0.13208647\n",
      "102: acrcuracy:0.75 loss: 0.1316589\n",
      "103: acrcuracy:0.75 loss: 0.13123178\n",
      "104: acrcuracy:0.75 loss: 0.13080513\n",
      "105: acrcuracy:0.75 loss: 0.13037889\n",
      "106: acrcuracy:0.75 loss: 0.12995304\n",
      "107: acrcuracy:0.75 loss: 0.12952755\n",
      "108: acrcuracy:0.75 loss: 0.12910241\n",
      "109: acrcuracy:0.75 loss: 0.1286776\n",
      "110: acrcuracy:0.75 loss: 0.12825309\n",
      "111: acrcuracy:0.75 loss: 0.12782887\n",
      "112: acrcuracy:0.75 loss: 0.12740497\n",
      "113: acrcuracy:0.75 loss: 0.12698133\n",
      "114: acrcuracy:0.75 loss: 0.126558\n",
      "115: acrcuracy:0.75 loss: 0.12613492\n",
      "116: acrcuracy:0.75 loss: 0.12571216\n",
      "117: acrcuracy:0.75 loss: 0.12528966\n",
      "118: acrcuracy:0.75 loss: 0.12486746\n",
      "119: acrcuracy:0.75 loss: 0.124445535\n",
      "120: acrcuracy:0.75 loss: 0.124023914\n",
      "121: acrcuracy:0.75 loss: 0.12360262\n",
      "122: acrcuracy:0.75 loss: 0.12318164\n",
      "123: acrcuracy:0.75 loss: 0.12276099\n",
      "124: acrcuracy:0.75 loss: 0.122340694\n",
      "125: acrcuracy:0.75 loss: 0.12192072\n",
      "126: acrcuracy:0.75 loss: 0.12150113\n",
      "127: acrcuracy:0.75 loss: 0.121081926\n",
      "128: acrcuracy:0.75 loss: 0.120663114\n",
      "129: acrcuracy:0.75 loss: 0.12024473\n",
      "130: acrcuracy:0.75 loss: 0.119826764\n",
      "131: acrcuracy:0.75 loss: 0.11940923\n",
      "132: acrcuracy:0.75 loss: 0.118992195\n",
      "133: acrcuracy:0.75 loss: 0.118575595\n",
      "134: acrcuracy:0.75 loss: 0.11815951\n",
      "135: acrcuracy:0.75 loss: 0.11774394\n",
      "136: acrcuracy:0.75 loss: 0.117328905\n",
      "137: acrcuracy:0.75 loss: 0.11691441\n",
      "138: acrcuracy:0.75 loss: 0.116500475\n",
      "139: acrcuracy:0.75 loss: 0.11608716\n",
      "140: acrcuracy:0.75 loss: 0.11567441\n",
      "141: acrcuracy:0.75 loss: 0.115262315\n",
      "142: acrcuracy:0.75 loss: 0.114850834\n",
      "143: acrcuracy:0.75 loss: 0.114440024\n",
      "144: acrcuracy:0.75 loss: 0.11402988\n",
      "145: acrcuracy:0.75 loss: 0.11362043\n",
      "146: acrcuracy:0.75 loss: 0.113211684\n",
      "147: acrcuracy:0.75 loss: 0.11280368\n",
      "148: acrcuracy:0.75 loss: 0.1123964\n",
      "149: acrcuracy:0.75 loss: 0.11198991\n",
      "150: acrcuracy:0.75 loss: 0.111584164\n",
      "151: acrcuracy:0.75 loss: 0.11117922\n",
      "152: acrcuracy:0.75 loss: 0.11077509\n",
      "153: acrcuracy:0.75 loss: 0.110371776\n",
      "154: acrcuracy:0.75 loss: 0.10996932\n",
      "155: acrcuracy:0.75 loss: 0.10956771\n",
      "156: acrcuracy:0.75 loss: 0.109166965\n",
      "157: acrcuracy:0.75 loss: 0.10876712\n",
      "158: acrcuracy:0.75 loss: 0.10836816\n",
      "159: acrcuracy:0.75 loss: 0.10797012\n",
      "160: acrcuracy:0.75 loss: 0.10757299\n",
      "161: acrcuracy:0.75 loss: 0.10717682\n",
      "162: acrcuracy:0.75 loss: 0.10678162\n",
      "163: acrcuracy:0.75 loss: 0.10638733\n",
      "164: acrcuracy:0.75 loss: 0.105994046\n",
      "165: acrcuracy:0.75 loss: 0.10560174\n",
      "166: acrcuracy:0.75 loss: 0.10521047\n",
      "167: acrcuracy:0.75 loss: 0.10482019\n",
      "168: acrcuracy:0.75 loss: 0.10443094\n",
      "169: acrcuracy:0.75 loss: 0.10404271\n",
      "170: acrcuracy:0.75 loss: 0.10365552\n",
      "171: acrcuracy:0.75 loss: 0.10326941\n",
      "172: acrcuracy:0.75 loss: 0.10288434\n",
      "173: acrcuracy:0.75 loss: 0.10250035\n",
      "174: acrcuracy:0.75 loss: 0.10211745\n",
      "175: acrcuracy:0.75 loss: 0.10173563\n",
      "176: acrcuracy:0.75 loss: 0.101354904\n",
      "177: acrcuracy:0.75 loss: 0.10097532\n",
      "178: acrcuracy:0.75 loss: 0.100596815\n",
      "179: acrcuracy:0.75 loss: 0.10021946\n",
      "180: acrcuracy:0.75 loss: 0.09984322\n",
      "181: acrcuracy:0.75 loss: 0.09946814\n",
      "182: acrcuracy:1.0 loss: 0.09909417\n",
      "183: acrcuracy:1.0 loss: 0.09872137\n",
      "184: acrcuracy:1.0 loss: 0.098349735\n",
      "185: acrcuracy:1.0 loss: 0.09797924\n",
      "186: acrcuracy:1.0 loss: 0.097609945\n",
      "187: acrcuracy:1.0 loss: 0.09724181\n",
      "188: acrcuracy:1.0 loss: 0.09687488\n",
      "189: acrcuracy:1.0 loss: 0.09650909\n",
      "190: acrcuracy:1.0 loss: 0.09614453\n",
      "191: acrcuracy:1.0 loss: 0.09578114\n",
      "192: acrcuracy:1.0 loss: 0.09541895\n",
      "193: acrcuracy:1.0 loss: 0.09505797\n",
      "194: acrcuracy:1.0 loss: 0.094698206\n",
      "195: acrcuracy:1.0 loss: 0.09433966\n",
      "196: acrcuracy:1.0 loss: 0.09398231\n",
      "197: acrcuracy:1.0 loss: 0.093626186\n",
      "198: acrcuracy:1.0 loss: 0.09327126\n",
      "199: acrcuracy:1.0 loss: 0.09291759\n",
      "200: acrcuracy:1.0 loss: 0.09256514\n",
      "201: acrcuracy:1.0 loss: 0.092213914\n",
      "202: acrcuracy:1.0 loss: 0.091863945\n",
      "203: acrcuracy:1.0 loss: 0.091515176\n",
      "204: acrcuracy:1.0 loss: 0.091167666\n",
      "205: acrcuracy:1.0 loss: 0.09082136\n",
      "206: acrcuracy:1.0 loss: 0.09047633\n",
      "207: acrcuracy:1.0 loss: 0.09013254\n",
      "208: acrcuracy:1.0 loss: 0.089789994\n",
      "209: acrcuracy:1.0 loss: 0.089448676\n",
      "210: acrcuracy:1.0 loss: 0.089108616\n",
      "211: acrcuracy:1.0 loss: 0.08876982\n",
      "212: acrcuracy:1.0 loss: 0.08843223\n",
      "213: acrcuracy:1.0 loss: 0.08809593\n",
      "214: acrcuracy:1.0 loss: 0.08776084\n",
      "215: acrcuracy:1.0 loss: 0.087427035\n",
      "216: acrcuracy:1.0 loss: 0.08709444\n",
      "217: acrcuracy:1.0 loss: 0.086763136\n",
      "218: acrcuracy:1.0 loss: 0.08643307\n",
      "219: acrcuracy:1.0 loss: 0.08610424\n",
      "220: acrcuracy:1.0 loss: 0.08577667\n",
      "221: acrcuracy:1.0 loss: 0.08545035\n",
      "222: acrcuracy:1.0 loss: 0.08512527\n",
      "223: acrcuracy:1.0 loss: 0.08480145\n",
      "224: acrcuracy:1.0 loss: 0.08447886\n",
      "225: acrcuracy:1.0 loss: 0.08415756\n",
      "226: acrcuracy:1.0 loss: 0.08383746\n",
      "227: acrcuracy:1.0 loss: 0.08351862\n",
      "228: acrcuracy:1.0 loss: 0.08320101\n",
      "229: acrcuracy:1.0 loss: 0.08288467\n",
      "230: acrcuracy:1.0 loss: 0.08256956\n",
      "231: acrcuracy:1.0 loss: 0.08225569\n",
      "232: acrcuracy:1.0 loss: 0.08194307\n",
      "233: acrcuracy:1.0 loss: 0.08163169\n",
      "234: acrcuracy:1.0 loss: 0.08132155\n",
      "235: acrcuracy:1.0 loss: 0.081012614\n",
      "236: acrcuracy:1.0 loss: 0.08070492\n",
      "237: acrcuracy:1.0 loss: 0.080398455\n",
      "238: acrcuracy:1.0 loss: 0.08009325\n",
      "239: acrcuracy:1.0 loss: 0.07978925\n",
      "240: acrcuracy:1.0 loss: 0.07948646\n",
      "241: acrcuracy:1.0 loss: 0.07918493\n",
      "242: acrcuracy:1.0 loss: 0.0788846\n",
      "243: acrcuracy:1.0 loss: 0.07858549\n",
      "244: acrcuracy:1.0 loss: 0.07828761\n",
      "245: acrcuracy:1.0 loss: 0.077990934\n",
      "246: acrcuracy:1.0 loss: 0.07769548\n",
      "247: acrcuracy:1.0 loss: 0.07740122\n",
      "248: acrcuracy:1.0 loss: 0.07710816\n",
      "249: acrcuracy:1.0 loss: 0.07681632\n",
      "250: acrcuracy:1.0 loss: 0.07652569\n",
      "251: acrcuracy:1.0 loss: 0.07623625\n",
      "252: acrcuracy:1.0 loss: 0.07594801\n",
      "253: acrcuracy:1.0 loss: 0.07566095\n",
      "254: acrcuracy:1.0 loss: 0.07537511\n",
      "255: acrcuracy:1.0 loss: 0.07509041\n",
      "256: acrcuracy:1.0 loss: 0.07480695\n",
      "257: acrcuracy:1.0 loss: 0.074524626\n",
      "258: acrcuracy:1.0 loss: 0.07424354\n",
      "259: acrcuracy:1.0 loss: 0.073963575\n",
      "260: acrcuracy:1.0 loss: 0.0736848\n",
      "261: acrcuracy:1.0 loss: 0.073407196\n",
      "262: acrcuracy:1.0 loss: 0.07313075\n",
      "263: acrcuracy:1.0 loss: 0.07285548\n",
      "264: acrcuracy:1.0 loss: 0.07258136\n",
      "265: acrcuracy:1.0 loss: 0.072308406\n",
      "266: acrcuracy:1.0 loss: 0.07203661\n",
      "267: acrcuracy:1.0 loss: 0.07176597\n",
      "268: acrcuracy:1.0 loss: 0.07149645\n",
      "269: acrcuracy:1.0 loss: 0.071228094\n",
      "270: acrcuracy:1.0 loss: 0.07096086\n",
      "271: acrcuracy:1.0 loss: 0.07069479\n",
      "272: acrcuracy:1.0 loss: 0.07042984\n",
      "273: acrcuracy:1.0 loss: 0.07016602\n",
      "274: acrcuracy:1.0 loss: 0.06990333\n",
      "275: acrcuracy:1.0 loss: 0.06964174\n",
      "276: acrcuracy:1.0 loss: 0.06938128\n",
      "277: acrcuracy:1.0 loss: 0.06912196\n",
      "278: acrcuracy:1.0 loss: 0.068863735\n",
      "279: acrcuracy:1.0 loss: 0.068606615\n",
      "280: acrcuracy:1.0 loss: 0.06835062\n",
      "281: acrcuracy:1.0 loss: 0.0680957\n",
      "282: acrcuracy:1.0 loss: 0.0678419\n",
      "283: acrcuracy:1.0 loss: 0.06758917\n",
      "284: acrcuracy:1.0 loss: 0.06733756\n",
      "285: acrcuracy:1.0 loss: 0.067087\n",
      "286: acrcuracy:1.0 loss: 0.066837564\n",
      "287: acrcuracy:1.0 loss: 0.066589154\n",
      "288: acrcuracy:1.0 loss: 0.06634186\n",
      "289: acrcuracy:1.0 loss: 0.06609562\n",
      "290: acrcuracy:1.0 loss: 0.06585046\n",
      "291: acrcuracy:1.0 loss: 0.06560635\n",
      "292: acrcuracy:1.0 loss: 0.06536331\n",
      "293: acrcuracy:1.0 loss: 0.065121315\n",
      "294: acrcuracy:1.0 loss: 0.06488037\n",
      "295: acrcuracy:1.0 loss: 0.0646405\n",
      "296: acrcuracy:1.0 loss: 0.06440164\n",
      "297: acrcuracy:1.0 loss: 0.06416385\n",
      "298: acrcuracy:1.0 loss: 0.06392705\n",
      "299: acrcuracy:1.0 loss: 0.06369133\n",
      "300: acrcuracy:1.0 loss: 0.063456625\n",
      "301: acrcuracy:1.0 loss: 0.063222945\n",
      "302: acrcuracy:1.0 loss: 0.06299028\n",
      "303: acrcuracy:1.0 loss: 0.062758625\n",
      "304: acrcuracy:1.0 loss: 0.062527984\n",
      "305: acrcuracy:1.0 loss: 0.062298372\n",
      "306: acrcuracy:1.0 loss: 0.06206974\n",
      "307: acrcuracy:1.0 loss: 0.06184213\n",
      "308: acrcuracy:1.0 loss: 0.0616155\n",
      "309: acrcuracy:1.0 loss: 0.06138988\n",
      "310: acrcuracy:1.0 loss: 0.06116524\n",
      "311: acrcuracy:1.0 loss: 0.060941577\n",
      "312: acrcuracy:1.0 loss: 0.060718916\n",
      "313: acrcuracy:1.0 loss: 0.06049722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314: acrcuracy:1.0 loss: 0.060276505\n",
      "315: acrcuracy:1.0 loss: 0.060056735\n",
      "316: acrcuracy:1.0 loss: 0.05983796\n",
      "317: acrcuracy:1.0 loss: 0.05962013\n",
      "318: acrcuracy:1.0 loss: 0.059403263\n",
      "319: acrcuracy:1.0 loss: 0.059187356\n",
      "320: acrcuracy:1.0 loss: 0.05897239\n",
      "321: acrcuracy:1.0 loss: 0.058758378\n",
      "322: acrcuracy:1.0 loss: 0.058545303\n",
      "323: acrcuracy:1.0 loss: 0.05833315\n",
      "324: acrcuracy:1.0 loss: 0.058121957\n",
      "325: acrcuracy:1.0 loss: 0.057911694\n",
      "326: acrcuracy:1.0 loss: 0.05770234\n",
      "327: acrcuracy:1.0 loss: 0.05749393\n",
      "328: acrcuracy:1.0 loss: 0.057286415\n",
      "329: acrcuracy:1.0 loss: 0.057079833\n",
      "330: acrcuracy:1.0 loss: 0.05687414\n",
      "331: acrcuracy:1.0 loss: 0.05666938\n",
      "332: acrcuracy:1.0 loss: 0.056465507\n",
      "333: acrcuracy:1.0 loss: 0.056262538\n",
      "334: acrcuracy:1.0 loss: 0.056060467\n",
      "335: acrcuracy:1.0 loss: 0.055859283\n",
      "336: acrcuracy:1.0 loss: 0.05565898\n",
      "337: acrcuracy:1.0 loss: 0.055459563\n",
      "338: acrcuracy:1.0 loss: 0.05526104\n",
      "339: acrcuracy:1.0 loss: 0.05506337\n",
      "340: acrcuracy:1.0 loss: 0.054866597\n",
      "341: acrcuracy:1.0 loss: 0.054670688\n",
      "342: acrcuracy:1.0 loss: 0.05447563\n",
      "343: acrcuracy:1.0 loss: 0.05428144\n",
      "344: acrcuracy:1.0 loss: 0.054088105\n",
      "345: acrcuracy:1.0 loss: 0.053895626\n",
      "346: acrcuracy:1.0 loss: 0.05370401\n",
      "347: acrcuracy:1.0 loss: 0.05351323\n",
      "348: acrcuracy:1.0 loss: 0.053323276\n",
      "349: acrcuracy:1.0 loss: 0.053134173\n",
      "350: acrcuracy:1.0 loss: 0.05294591\n",
      "351: acrcuracy:1.0 loss: 0.05275847\n",
      "352: acrcuracy:1.0 loss: 0.052571867\n",
      "353: acrcuracy:1.0 loss: 0.05238607\n",
      "354: acrcuracy:1.0 loss: 0.0522011\n",
      "355: acrcuracy:1.0 loss: 0.05201695\n",
      "356: acrcuracy:1.0 loss: 0.051833615\n",
      "357: acrcuracy:1.0 loss: 0.051651098\n",
      "358: acrcuracy:1.0 loss: 0.05146935\n",
      "359: acrcuracy:1.0 loss: 0.051288433\n",
      "360: acrcuracy:1.0 loss: 0.051108308\n",
      "361: acrcuracy:1.0 loss: 0.050928976\n",
      "362: acrcuracy:1.0 loss: 0.050750438\n",
      "363: acrcuracy:1.0 loss: 0.050572686\n",
      "364: acrcuracy:1.0 loss: 0.050395723\n",
      "365: acrcuracy:1.0 loss: 0.05021953\n",
      "366: acrcuracy:1.0 loss: 0.05004412\n",
      "367: acrcuracy:1.0 loss: 0.04986947\n",
      "368: acrcuracy:1.0 loss: 0.049695607\n",
      "369: acrcuracy:1.0 loss: 0.049522493\n",
      "370: acrcuracy:1.0 loss: 0.04935014\n",
      "371: acrcuracy:1.0 loss: 0.04917856\n",
      "372: acrcuracy:1.0 loss: 0.049007732\n",
      "373: acrcuracy:1.0 loss: 0.04883765\n",
      "374: acrcuracy:1.0 loss: 0.048668325\n",
      "375: acrcuracy:1.0 loss: 0.048499733\n",
      "376: acrcuracy:1.0 loss: 0.04833189\n",
      "377: acrcuracy:1.0 loss: 0.04816478\n",
      "378: acrcuracy:1.0 loss: 0.04799842\n",
      "379: acrcuracy:1.0 loss: 0.047832776\n",
      "380: acrcuracy:1.0 loss: 0.04766786\n",
      "381: acrcuracy:1.0 loss: 0.047503673\n",
      "382: acrcuracy:1.0 loss: 0.047340207\n",
      "383: acrcuracy:1.0 loss: 0.04717745\n",
      "384: acrcuracy:1.0 loss: 0.047015417\n",
      "385: acrcuracy:1.0 loss: 0.046854094\n",
      "386: acrcuracy:1.0 loss: 0.04669347\n",
      "387: acrcuracy:1.0 loss: 0.046533566\n",
      "388: acrcuracy:1.0 loss: 0.04637435\n",
      "389: acrcuracy:1.0 loss: 0.046215832\n",
      "390: acrcuracy:1.0 loss: 0.046058014\n",
      "391: acrcuracy:1.0 loss: 0.045900878\n",
      "392: acrcuracy:1.0 loss: 0.04574445\n",
      "393: acrcuracy:1.0 loss: 0.04558868\n",
      "394: acrcuracy:1.0 loss: 0.04543361\n",
      "395: acrcuracy:1.0 loss: 0.04527921\n",
      "396: acrcuracy:1.0 loss: 0.045125477\n",
      "397: acrcuracy:1.0 loss: 0.044972427\n",
      "398: acrcuracy:1.0 loss: 0.044820044\n",
      "399: acrcuracy:1.0 loss: 0.04466834\n",
      "400: acrcuracy:1.0 loss: 0.044517275\n",
      "401: acrcuracy:1.0 loss: 0.044366885\n",
      "402: acrcuracy:1.0 loss: 0.044217143\n",
      "403: acrcuracy:1.0 loss: 0.044068057\n",
      "404: acrcuracy:1.0 loss: 0.04391962\n",
      "405: acrcuracy:1.0 loss: 0.04377183\n",
      "406: acrcuracy:1.0 loss: 0.043624684\n",
      "407: acrcuracy:1.0 loss: 0.043478172\n",
      "408: acrcuracy:1.0 loss: 0.0433323\n",
      "409: acrcuracy:1.0 loss: 0.043187074\n",
      "410: acrcuracy:1.0 loss: 0.043042477\n",
      "411: acrcuracy:1.0 loss: 0.04289849\n",
      "412: acrcuracy:1.0 loss: 0.04275515\n",
      "413: acrcuracy:1.0 loss: 0.042612426\n",
      "414: acrcuracy:1.0 loss: 0.042470317\n",
      "415: acrcuracy:1.0 loss: 0.04232883\n",
      "416: acrcuracy:1.0 loss: 0.042187948\n",
      "417: acrcuracy:1.0 loss: 0.042047687\n",
      "418: acrcuracy:1.0 loss: 0.041908026\n",
      "419: acrcuracy:1.0 loss: 0.04176897\n",
      "420: acrcuracy:1.0 loss: 0.041630518\n",
      "421: acrcuracy:1.0 loss: 0.041492652\n",
      "422: acrcuracy:1.0 loss: 0.041355405\n",
      "423: acrcuracy:1.0 loss: 0.04121874\n",
      "424: acrcuracy:1.0 loss: 0.041082673\n",
      "425: acrcuracy:1.0 loss: 0.04094718\n",
      "426: acrcuracy:1.0 loss: 0.040812287\n",
      "427: acrcuracy:1.0 loss: 0.04067796\n",
      "428: acrcuracy:1.0 loss: 0.040544223\n",
      "429: acrcuracy:1.0 loss: 0.04041106\n",
      "430: acrcuracy:1.0 loss: 0.040278476\n",
      "431: acrcuracy:1.0 loss: 0.040146455\n",
      "432: acrcuracy:1.0 loss: 0.04001501\n",
      "433: acrcuracy:1.0 loss: 0.03988413\n",
      "434: acrcuracy:1.0 loss: 0.0397538\n",
      "435: acrcuracy:1.0 loss: 0.039624043\n",
      "436: acrcuracy:1.0 loss: 0.03949483\n",
      "437: acrcuracy:1.0 loss: 0.03936619\n",
      "438: acrcuracy:1.0 loss: 0.03923809\n",
      "439: acrcuracy:1.0 loss: 0.039110538\n",
      "440: acrcuracy:1.0 loss: 0.03898354\n",
      "441: acrcuracy:1.0 loss: 0.03885709\n",
      "442: acrcuracy:1.0 loss: 0.038731176\n",
      "443: acrcuracy:1.0 loss: 0.038605787\n",
      "444: acrcuracy:1.0 loss: 0.038480945\n",
      "445: acrcuracy:1.0 loss: 0.038356647\n",
      "446: acrcuracy:1.0 loss: 0.038232874\n",
      "447: acrcuracy:1.0 loss: 0.038109627\n",
      "448: acrcuracy:1.0 loss: 0.037986893\n",
      "449: acrcuracy:1.0 loss: 0.037864707\n",
      "450: acrcuracy:1.0 loss: 0.037743017\n",
      "451: acrcuracy:1.0 loss: 0.03762186\n",
      "452: acrcuracy:1.0 loss: 0.03750121\n",
      "453: acrcuracy:1.0 loss: 0.037381086\n",
      "454: acrcuracy:1.0 loss: 0.037261464\n",
      "455: acrcuracy:1.0 loss: 0.03714234\n",
      "456: acrcuracy:1.0 loss: 0.037023738\n",
      "457: acrcuracy:1.0 loss: 0.03690564\n",
      "458: acrcuracy:1.0 loss: 0.036788043\n",
      "459: acrcuracy:1.0 loss: 0.036670934\n",
      "460: acrcuracy:1.0 loss: 0.03655432\n",
      "461: acrcuracy:1.0 loss: 0.036438227\n",
      "462: acrcuracy:1.0 loss: 0.036322597\n",
      "463: acrcuracy:1.0 loss: 0.036207467\n",
      "464: acrcuracy:1.0 loss: 0.03609282\n",
      "465: acrcuracy:1.0 loss: 0.035978664\n",
      "466: acrcuracy:1.0 loss: 0.035864986\n",
      "467: acrcuracy:1.0 loss: 0.035751782\n",
      "468: acrcuracy:1.0 loss: 0.035639063\n",
      "469: acrcuracy:1.0 loss: 0.03552682\n",
      "470: acrcuracy:1.0 loss: 0.035415042\n",
      "471: acrcuracy:1.0 loss: 0.03530373\n",
      "472: acrcuracy:1.0 loss: 0.0351929\n",
      "473: acrcuracy:1.0 loss: 0.035082527\n",
      "474: acrcuracy:1.0 loss: 0.03497261\n",
      "475: acrcuracy:1.0 loss: 0.03486316\n",
      "476: acrcuracy:1.0 loss: 0.034754172\n",
      "477: acrcuracy:1.0 loss: 0.034645654\n",
      "478: acrcuracy:1.0 loss: 0.034537565\n",
      "479: acrcuracy:1.0 loss: 0.03442994\n",
      "480: acrcuracy:1.0 loss: 0.03432278\n",
      "481: acrcuracy:1.0 loss: 0.034216046\n",
      "482: acrcuracy:1.0 loss: 0.03410977\n",
      "483: acrcuracy:1.0 loss: 0.034003943\n",
      "484: acrcuracy:1.0 loss: 0.033898547\n",
      "485: acrcuracy:1.0 loss: 0.033793595\n",
      "486: acrcuracy:1.0 loss: 0.03368909\n",
      "487: acrcuracy:1.0 loss: 0.033585012\n",
      "488: acrcuracy:1.0 loss: 0.033481356\n",
      "489: acrcuracy:1.0 loss: 0.033378143\n",
      "490: acrcuracy:1.0 loss: 0.033275362\n",
      "491: acrcuracy:1.0 loss: 0.033173\n",
      "492: acrcuracy:1.0 loss: 0.033071063\n",
      "493: acrcuracy:1.0 loss: 0.032969557\n",
      "494: acrcuracy:1.0 loss: 0.03286846\n",
      "495: acrcuracy:1.0 loss: 0.032767788\n",
      "496: acrcuracy:1.0 loss: 0.03266753\n",
      "497: acrcuracy:1.0 loss: 0.03256769\n",
      "498: acrcuracy:1.0 loss: 0.032468263\n",
      "499: acrcuracy:1.0 loss: 0.03236924\n",
      "500: acrcuracy:1.0 loss: 0.03227063\n",
      "max test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = 0.0\n",
    "\n",
    "def training_step(i):#, update_test_data, update_train_data):\n",
    "    \n",
    "    global max_accuracy\n",
    "    \n",
    "    a, c, _ = sess.run([accuracy, cross_entropy, train_step], feed_dict = {X:input_data, Y_:label})\n",
    "    if(a>max_accuracy):\n",
    "        max_accuracy = a\n",
    "    print(str(i) + \": acrcuracy:\" + str(a) + \" loss: \" + str(c))\n",
    "    \n",
    "for i in range(500+1):\n",
    "    training_step(i)\n",
    "print(\"max test accuracy: \" + str(max_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.] [0.]\n",
      "[0. 1.] [1.]\n",
      "[1. 0.] [1.]\n",
      "[1. 1.] [1.]\n"
     ]
    }
   ],
   "source": [
    "y  = sess.run(predict, feed_dict = {X:input_data, Y_:label})\n",
    "for i in range(4):\n",
    "    print(input_data[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1.8]",
   "language": "python",
   "name": "conda-env-tf1.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
